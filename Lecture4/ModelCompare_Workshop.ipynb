{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "812f29c3-3241-42e5-bebc-f8c1252559bc",
   "metadata": {},
   "source": [
    "# Testing different models on unseen data\n",
    "\n",
    "This playbook constructs some simple CNN, DNN and Transformer based models with the normal mnist training dataset and a modified version of the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bdaae1-b4d8-4c10-9f19-df857bfa8e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The normal imports for this task\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931ce8cb-c89f-41b7-8543-515b0fa5e5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cpu\")#\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478e7116-931f-400b-8d01-cc0cc0dccc20",
   "metadata": {},
   "source": [
    "## Load our MNist data\n",
    "\n",
    "Unlike before this time we will normalize our input data more 'correctly'.\n",
    "\n",
    "We want the 'normal' mnist numerical training data.\n",
    "\n",
    "We also want to load the test dataset using a complex set of transforms. This helps evaluate the model performance on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d3e9b5-2184-4e9f-bb82-4306a91a8e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset without normalization\n",
    "mnist_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "# Load entire dataset in one batch\n",
    "data_loader = DataLoader(mnist_dataset, batch_size=len(mnist_dataset), shuffle=False)\n",
    "# Get all images in a single batch\n",
    "images, _ = next(iter(data_loader))  # Shape: (60000, 1, 28, 28)\n",
    "\n",
    "# Calculate mean and standard deviation\n",
    "mean = ## FINISH_ME ## Calculate the mean over all input pixels\n",
    "std = images.std().item() ## Stddev from all input pixels\n",
    "\n",
    "# Transform: Convert images to tensors and normalize, but this time to the dataset mean and stddev\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Converts to [0, 1]\n",
    "    transforms.Normalize((mean,), (std,))\n",
    "])\n",
    "\n",
    "# Load MNIST dataset\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "# Transform: Convert images to tensors and normalize\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.RandomRotation(degrees= ## FINISH_ME ##, expand=False), # Random rotation of up to 20deg\n",
    "    transforms.RandomAffine(degrees=0, translate= ## FINISH_ME ## ),  # Random shifts (up to 15% of image size)\n",
    "    transforms.RandomResizedCrop(size=28, scale= ## FINISH_ME ## ),   # Random scaling (85% to 115% of original size)\n",
    "    transforms.ColorJitter(brightness= , contrast= ),      # Adjust brightness & contrast slightly (factor 0.2)\n",
    "    transforms.ToTensor(),  # Converts to [0, 1]\n",
    "    transforms.Normalize((mean,), (std,))\n",
    "])\n",
    "\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8afc04a-721b-4359-b769-9722fe509a1b",
   "metadata": {},
   "source": [
    "# Build Our models\n",
    "\n",
    "Lets Build a DNN, CNN and transformer based model for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a7a832-8612-477b-9bf3-c2f41c015f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a DNN network which goes from 784 -> 512 -> 128 -> 64 -> 10\n",
    "DNN_Model = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(784, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear( ## FINISH_ME ##\n",
    "            nn.ReLU(),\n",
    "            nn.Linear( ## FINISH_ME ##\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 10)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83145ec9-7142-4159-94fe-df9219fec2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a simple CNN which goes from (n,1,28,28)->(n,32,14,14)->(n,64,7,7) --> 64*7*7 -> 128 -> 64 -> 10\n",
    "CNN_Model = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1),  # Output: 16 x 14 x 14\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d( ## FINISH_ME ## kernel_size=3, stride=2, padding=1), # Output: 32 x 7 x 7\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear( ## FINISH_ME ##\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 10)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981c5859-145d-45b8-ac34-4dd492c23ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Transformer Encoder Layer\n",
    "# This defines our core transformer as 128dim, 4heads, 128dim-ff, dropout0.1\n",
    "encoder_layer = nn.TransformerEncoderLayer(d_model=128, nhead=4, dim_feedforward=128, dropout=0.1)\n",
    "transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=5)\n",
    "\n",
    "TF_Model = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(784, 128),      # Pseudo-Embedding layer\n",
    "            transformer_encoder,          # MHA Transformer defined above\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, 128),        # Taking output from MHA layer for projecting to decision\n",
    "            nn.ReLU(),\n",
    "            nn.Linear( ## FINISH_ME ##\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 10)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ec5b60-ba49-4755-8893-05873db268b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build our models and print them for understanding\n",
    "dnn_model = DNN_Model.to(device)\n",
    "cnn_model = CNN_Model.to(device)\n",
    "tf_model = TF_Model.to(device)\n",
    "\n",
    "# Dummy batch (e.g., MNIST-like grayscale images)\n",
    "dummy_images = torch.randn(16, 1, 28, 28).to(device)  # (batch_size=16, height=28, width=28)\n",
    "logits = dnn_model(dummy_images)\n",
    "print('DNN Model:')\n",
    "print(dnn_model)\n",
    "\n",
    "# Dummy batch (e.g., MNIST-like grayscale images)\n",
    "dummy_images = torch.randn(16, 1, 28, 28).to(device)  # (batch_size=16, height=28, width=28)\n",
    "logits = cnn_model(dummy_images)\n",
    "print('CNN Model:')\n",
    "print(cnn_model)\n",
    "\n",
    "# Dummy batch (e.g., MNIST-like grayscale images)\n",
    "dummy_images = torch.randn(16, 1, 28, 28).to(device)  # (batch_size=16, height=28, width=28)\n",
    "logits = tf_model(dummy_images)\n",
    "print('Transformer Model:')\n",
    "print(tf_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9292620c-3bff-4f8c-9a49-f24641412681",
   "metadata": {},
   "source": [
    "## Train our models\n",
    "\n",
    "As before, train each model over the mnist train dataset. No need to track acc/validation as this isn't too important this-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff71659-c693-45f7-ab79-c1d0f91ef67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we train our DNN\n",
    "\n",
    "dnn_criterion = nn.CrossEntropyLoss()\n",
    "dnn_optimizer = optim.Adam(dnn_model.parameters(), lr=learning_rate)\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    dnn_model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    # Per-batch\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Evaluate, Loss, Backwards, Step\n",
    "        dnn_optimizer.zero_grad()\n",
    "        outputs = ## FINISH_ME ##\n",
    "        loss = dnn_criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        dnn_optimizer.step()\n",
    "\n",
    "        # Track losses\n",
    "        total_loss += loss.item()\n",
    "    print(f'DNN Classifier Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(train_loader):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf8af9a-fc66-4297-8114-312fde0cdd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we train our CNN\n",
    "\n",
    "cnn_criterion = nn.CrossEntropyLoss()\n",
    "cnn_optimizer = optim.Adam(cnn_model.parameters(), lr=learning_rate)\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    cnn_model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    # Per-batch\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Evaluate, Loss, Backwards, Step\n",
    "        cnn_optimizer.zero_grad()\n",
    "        outputs = ## FINISH_ME ##\n",
    "        loss = cnn_criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        cnn_optimizer.step()\n",
    "\n",
    "        # Track losses\n",
    "        total_loss += loss.item()\n",
    "    print(f'CNN Classifier Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(train_loader):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49629a07-d402-4ada-952a-028dd1039b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we train our Transformer\n",
    "\n",
    "tf_criterion = nn.CrossEntropyLoss()\n",
    "tf_optimizer = optim.Adam(tf_model.parameters(), lr=learning_rate)\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    tf_model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    # Per-batch\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Evaluate, Loss, Backwards, Step\n",
    "        tf_optimizer.zero_grad()\n",
    "        outputs = ## FINISH_ME ##\n",
    "        loss = tf_criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        tf_optimizer.step()\n",
    "\n",
    "        # Track losses\n",
    "        total_loss += loss.item()\n",
    "    print(f'Transformer Classifier Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(train_loader):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07b6942-8fbd-4920-be99-9379910e498b",
   "metadata": {},
   "source": [
    "## Evaluate our model on un-seen test data\n",
    "\n",
    "Our test dataset has been defined differently this time.\n",
    "\n",
    "We have introduced random noise/rotation/saturation/brightness jitter.\n",
    "\n",
    "This helps show how well our model copes with completely unseen, non-perfect inputs.\n",
    "\n",
    "We will run through this randomized input dataset 5 times to reduce statistical randomness giving us a bad idea of how accurate our model is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b15f530-7aca-4883-be22-5569eaec6d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation on the test set\n",
    "\n",
    "dnn_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for _ in range(5):\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = dnn_model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += ## FINISH_ME ##\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'DNN Accuracy on adjusted MNIST test set: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4a4d02-f150-4db3-b72a-4cfe7b6c54c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation on the test set\n",
    "cnn_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for _ in range(5):\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "\n",
    "            outputs = cnn_model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += ## FINISH_ME ##\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'CNN Accuracy on adjusted MNIST test set: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca64e97a-4ef1-4a9f-a4cd-fb01963c76f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation on the test set\n",
    "tf_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for _ in range(5):\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = tf_model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += ## FINISH_ME ##\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Transformer Accuracy on adjusted MNIST test set: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcf3948-52ec-4d8a-91f3-d9bf25eda921",
   "metadata": {},
   "source": [
    "## Output\n",
    "\n",
    "You should probably see something like the following:\n",
    "\n",
    "| Model | Accuracy |\n",
    "| --- | --- |\n",
    "| DNN | 50% |\n",
    "| CNN | 60% |\n",
    "| Transformer | 50% |\n",
    "\n",
    "The DNN and transformer models are entirely relient on the structure of 'where' the information on the input is.\n",
    "The CNN however is able to pick out patterns more effectively and perform better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e7af8c-6ae0-47fc-a51c-b66038bb299e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
